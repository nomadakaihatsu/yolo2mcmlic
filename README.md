# 動画解析のための物体検出モデルとマルチチャネルマルチラベル分類モデルの統合モデル
## 概要
- 物体検出モデルとマルチチャネルマルチラベル分類モデルを統合したモデルです。
- 動画を入力とし、物体検出結果を固定長変換のうえ、マルチチャネルマルチラベル分類モデルに入力し、物体検出結果のクラス分類を行います。
- マルチラベル分類モデルで2DConvを使用する場合と、 3DConvを使用する場合の2パターンで固定長変換方法を切り替えます。
  - 2DConvを使用する場合
    - 固定長変換： [フーレム数,物体検出結果*]の入力を受け取り、[物体検出ラベル数,224,224]の出力を返す必要があります。
    - フレームの次元を圧縮するための方法は以下。
      - 時間軸方向への重み付きの加重移動平均
      - その他適宜トライアルにより追加
    - マルチチャネルマルチラベル分類モデル：mcmlic(2dconv)
　　   - [バッチサイズ,物体検出ラベル数,224,224]の入力を受け取り、[バッチサイズ,作業分類ラベル数]の出力を返す。
  - 3DConvを使用する場合
    - 固定長変換：複数フレームの物体検出結果をマルチチャネルイメージに変換します
      - [フーレム数,物体検出結果*]の入力を受け取り、[フレーム数,物体検出ラベル数,224,224]の出力を返す必要があります。
    - マルチチャネルマルチラベル分類モデル：mcmlic(3dconv)
      - [バッチサイズ,フレーム数,物体検出ラベル数,224,224]の入力を受け取り、[バッチサイズ,作業分類ラベル数]の出力を返す。

### モジュール構成
- ルート：YOLO2MCMLIC
  - 物体検出モジュール：yolov7
  - 物体検出結果の固定長変換モジュール：detections2mci
  - マルチチャネルマルチラベル分類モジュール：mcmlic
### 使い方
以下のコマンドをYOLO2MCMLICから実行します。
- create_mci_dataset.py
  - 学習済みのyoloモデルを使用して、物体検出結果を固定長変換したデータセットを作成します。
  - 作成したデータは物体検出ラベルごとに可視化します。
  - 入力
    - yolo7モデル
    - 動画データ
  - 出力
    - 固定長変換したデータセット(pt)＠ファイル単位＝フレーム単位
    - デモ出力として、入力動画に物体検出結果を重ねた画像と、固定変換長データの各チャネルの画像を並べて出力します。
- crate_mcmlic_label.py
  - csvで作成した作業チャートを使用して、特定のフレームに対応する作業分類ラベル出力します。
  - 海洋作業分析を前提としています。
  - 入力
    - 作業チャート(csv)
  - 出力
    - 作業分類ラベル(csv)＠ファイル単位＝フレーム単位
- train_mcmlic.py
  - create_mci_datasetで生成したデータセットとcrate_mcmlic_labelで作成したラベルデータを使用して、
    マルチチャネルマルチラベル分類モデルを学習します。
  - 入力
    - 学習データセット
    - 学習ラベルデータ
    - 学習設定ファイル
  - 出力
    - 学習済みMCMLICモデル
    - 学習曲線
    - 学習済みモデルの評価結果
- predict.py
  - 学習済みの物体検出モデルとマルチチャネルマルチ分類モデルを使用して、動画の物体検出結果とクラス分類結果を出力します。
  - 入力
    - 学習済みMCMLICモデル
    - 学習済みyolo7モデル
    - 動画データ
  - 出力
    - 推論結果の時系列データ(csv)
    - 入力動画に物体検出結果及び推論結果を重ねた動画(mp4)
    - デモ出力として、入力動画に物体検出結果を重ね、正解データ、推論結果を追加した動画(mp4)
    - デモ出力として、正解ラベル、推論ラベル、物体検出ラベルのフラグを時系列出力したデータ(csv)
物体検出モデルの学習はyolo7ディレクトリから、train.pyを実行します。(通常のyolo7の学習と同じです)